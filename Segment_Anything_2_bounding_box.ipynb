{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f302e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/User/Desktop/SAM_2/segmented_output\\can-you-have-too-many-kittens_segmented_0.png\n",
      "Saved mask: C:/Users/User/Desktop/SAM_2/segmented_output\\can-you-have-too-many-kittens_mask_0.png\n",
      "Saved: C:/Users/User/Desktop/SAM_2/segmented_output\\can-you-have-too-many-kittens_segmented_1.png\n",
      "Saved mask: C:/Users/User/Desktop/SAM_2/segmented_output\\can-you-have-too-many-kittens_mask_1.png\n",
      "Saved: C:/Users/User/Desktop/SAM_2/segmented_output\\can-you-have-too-many-kittens_segmented_2.png\n",
      "Saved mask: C:/Users/User/Desktop/SAM_2/segmented_output\\can-you-have-too-many-kittens_mask_2.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "# Paths\n",
    "checkpoint = \"C:/Users/User/Desktop/SAM_2/sam2/checkpoints/sam2.1_hiera_large.pt\"\n",
    "model_cfg = \"C:/Users/User/Desktop/SAM_2/sam2/sam2/configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "image_path = \"C:/Users/User/Desktop/SAM_2/images/can-you-have-too-many-kittens.png\"\n",
    "output_folder = \"C:/Users/User/Desktop/SAM_2/segmented_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Check file existence\n",
    "if not os.path.exists(model_cfg):\n",
    "    raise FileNotFoundError(f\"Config file not found at {model_cfg}\")\n",
    "if not os.path.exists(checkpoint):\n",
    "    raise FileNotFoundError(f\"Checkpoint file not found at {checkpoint}\")\n",
    "if not os.path.exists(image_path):\n",
    "    raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
    "\n",
    "# Load and convert image\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    raise ValueError(f\"Image at {image_path} could not be loaded.\")\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "clone = image.copy()  # This is used to temporarily draw on\n",
    "\n",
    "# Variables for drawing\n",
    "ref_points = []  # List to store multiple bounding boxes\n",
    "drawing = False\n",
    "\n",
    "# Mouse callback function\n",
    "def draw_rectangle(event, x, y, flags, param):\n",
    "    global ref_points, drawing, clone  # Use clone to not overwrite the original image\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ref_points.append([(x, y)])  # Start a new box\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and drawing:\n",
    "        temp_img = clone.copy()  # Create a fresh copy of the image each time\n",
    "        cv2.rectangle(temp_img, ref_points[-1][0], (x, y), (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Draw Bounding Box\", temp_img)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        ref_points[-1].append((x, y))  # Finish the current box\n",
    "        cv2.rectangle(clone, ref_points[-1][0], ref_points[-1][1], (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Draw Bounding Box\", clone)\n",
    "\n",
    "# Show image and wait for user input\n",
    "cv2.namedWindow(\"Draw Bounding Box\")\n",
    "cv2.setMouseCallback(\"Draw Bounding Box\", draw_rectangle)\n",
    "cv2.imshow(\"Draw Bounding Box\", clone)\n",
    "\n",
    "# Main loop for key events\n",
    "while True:\n",
    "    key = cv2.waitKey(1) & 0xFF  # Wait for a key press\n",
    "    if key == ord('u'):  # Press 'u' to undo the last bounding box\n",
    "        if len(ref_points) > 0:\n",
    "            ref_points.pop()  # Remove the last drawn bounding box\n",
    "            clone = image.copy()  # Reset image to original\n",
    "            for box in ref_points:  # Redraw the remaining bounding boxes\n",
    "                cv2.rectangle(clone, box[0], box[1], (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Draw Bounding Box\", clone)\n",
    "    elif key == 13:  # Press 'Enter' to finish drawing\n",
    "        break  # Exit the loop once finished\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Ensure that the user drew at least one bounding box\n",
    "if len(ref_points) == 0 or any(len(pt) != 2 for pt in ref_points):\n",
    "    raise ValueError(\"At least one bounding box must be drawn.\")\n",
    "\n",
    "# Initialize the predictor\n",
    "try:\n",
    "    predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))\n",
    "except Exception as e:\n",
    "    print(f\"Error during SAM2 model initialization: {e}\")\n",
    "    raise\n",
    "\n",
    "# Get the base filename without extension\n",
    "base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "# Run inference for each bounding box\n",
    "for idx, (pt1, pt2) in enumerate(ref_points):\n",
    "    bbox = [min(pt1[0], pt2[0]), min(pt1[1], pt2[1]), max(pt1[0], pt2[0]), max(pt1[1], pt2[1])]\n",
    "\n",
    "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "        predictor.set_image(image_rgb)\n",
    "        masks, scores, _ = predictor.predict(box=bbox)\n",
    "\n",
    "    if masks is not None and len(masks) > 0:\n",
    "        # Get the index of the highest confidence mask\n",
    "        best_idx = scores.argmax().item()\n",
    "        best_mask = masks[best_idx]\n",
    "\n",
    "        if best_mask is None or not np.any(best_mask):\n",
    "            print(f\"Best mask for bounding box {idx} is empty. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Create a full-size mask with the same dimensions as the input image\n",
    "        full_size_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "        # Place the best mask within the bounding box\n",
    "        mask_crop = best_mask[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "        full_size_mask[bbox[1]:bbox[3], bbox[0]:bbox[2]] = mask_crop\n",
    "\n",
    "        # Set the mask region to white (255)\n",
    "        full_size_mask[full_size_mask > 0] = 255\n",
    "\n",
    "        # Apply the full-size mask to the original image\n",
    "        masked = cv2.bitwise_and(image, image, mask=full_size_mask)\n",
    "\n",
    "        if masked is None or masked.size == 0:\n",
    "            print(f\"Masked image for bbox {idx} is empty. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Save results\n",
    "        output_filename = f\"{base_filename}_segmented_{idx}.png\"\n",
    "        output_full_path = os.path.join(output_folder, output_filename)\n",
    "        cv2.imwrite(output_full_path, masked)\n",
    "        print(f\"Saved: {output_full_path}\")\n",
    "\n",
    "        mask_filename = f\"{base_filename}_mask_{idx}.png\"\n",
    "        mask_full_path = os.path.join(output_folder, mask_filename)\n",
    "        cv2.imwrite(mask_full_path, full_size_mask)\n",
    "        print(f\"Saved mask: {mask_full_path}\")\n",
    "\n",
    "        # Optional: Display\n",
    "        cv2.imshow(f\"Segmented {idx}\", masked)\n",
    "        cv2.imshow(f\"Mask {idx}\", full_size_mask)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
